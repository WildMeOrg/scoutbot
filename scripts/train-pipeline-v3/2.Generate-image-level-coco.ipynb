{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "\n",
    "- Intent is to generate full-image level JSON COCO files for train and test set. This files will be used by the slicing script. Slicing script will generate a tile-level COCO file.\n",
    "\n",
    "- Working with two datafarmes - dfa and dfi. The fields of these dataframes correspond to 'annotations' and images fields in the COCO files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point to data files processed from notebook 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/l3404/Mate/kaza_files/kaza_export_v0'\n",
    "img_dir = os.path.join(data_dir, 'exports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(data_dir, 'kaza_train_v0.csv'))\n",
    "df_test = pd.read_csv(os.path.join(data_dir, 'kaza_test_v0.csv'))\n",
    "\n",
    "dfa = pd.read_csv(os.path.join(data_dir, 'dfa_kaza_v0.csv'))\n",
    "dfi = pd.read_csv(os.path.join(data_dir, 'dfi_kaza_v0.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate metadata fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    5325\n",
       "Name: file_path, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfi['file_path'] = dfi['file_name'].apply(lambda x: os.path.abspath(os.path.join(img_dir, x)))\n",
    "\n",
    "dfi['file_path'].apply(lambda x: os.path.exists(x)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Csv saves the list of bbox coordinates as string. Need to serialize\n",
    "\n",
    "dfa['bbox'] = dfa['bbox'].apply(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode annot-level and image-level 'ids' into yolo-compatible ids (from 0 to N)\n",
    "\n",
    "- Coco datasets in general rely on indexing on two levels - annotations and images. Thus far composide IDs have been used to avoid collision. Though they must be converted in a uniform, 0 to N range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SH06_1', 'SH06_2', 'SH06_3', ..., 'SH09_83', 'SH09_84', 'SH09_85'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to convert these annot IDs to 0, 1, 2, 3, ... N\n",
    "\n",
    "dfa['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SH06_1', 'SH06_2', 'SH06_3', ..., 'SH09_26', 'SH09_27', 'SH09_28'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same for image IDs\n",
    "\n",
    "dfi['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15480, 15480)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit label encoder on full set annotation IDs\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(dfa['id'].values)\n",
    "dfa['id'] = le.transform(dfa['id'])\n",
    "dfa = dfa.sort_values(by=['id'])\n",
    "dfa['id'].nunique(), len(dfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12299 12299\n",
      "3181 3181\n"
     ]
    }
   ],
   "source": [
    "# Convert train and test set annot ids\n",
    "\n",
    "train_ids = df_train['id_x'].dropna().unique()\n",
    "train_ids = le.transform(train_ids)\n",
    "print(len(train_ids), df_train['id_x'].notna().sum())\n",
    "\n",
    "test_ids = df_test['id_x'].dropna().unique()\n",
    "test_ids = le.transform(test_ids)\n",
    "print(len(test_ids), df_test['id_x'].notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all annots point to the right image ids\n",
    "assert len(dfa['image_id'].unique()) == len(np.intersect1d(dfi['id'].unique(), dfa['image_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated images:  2483\n",
      "All images:  5325\n"
     ]
    }
   ],
   "source": [
    "# Counts of images with annots and all images (empty + annotated)\n",
    "# We don't really need more empty images since they are going to be subsampled anyways\n",
    "\n",
    "print('Annotated images: ', dfa['image_id'].nunique())\n",
    "print('All images: ', dfi['id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5325, 5325)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit label encoder on full set image IDs\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(dfi['id'].values)\n",
    "dfi['id'] = le.transform(dfi['id'])\n",
    "dfi = dfi.sort_values(by=['id'])\n",
    "dfi['id'].nunique(), len(dfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['image_id'] = le.transform(dfa['image_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4260 4260\n",
      "1065 1065\n"
     ]
    }
   ],
   "source": [
    "train_imgids = df_train['id_y'].unique()\n",
    "train_imgids = le.transform(train_imgids)\n",
    "print(len(train_imgids), df_train['id_y'].nunique())\n",
    "\n",
    "test_imgids = df_test['id_y'].unique()\n",
    "test_imgids = le.transform(test_imgids)\n",
    "print(len(test_imgids), df_test['id_y'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the image to annot mapping is valid (the number of annots should stay the same during merge)\n",
    "\n",
    "assert dfa.merge(dfi, left_on='image_id', right_on='id', how='right').shape[0] == pd.concat([df_train, df_test]).shape[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18322, 22), (18322, 29))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.merge(dfi, left_on='image_id', right_on='id', how='right').shape, pd.concat([df_train, df_test]).shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty column(s) (might be redundant)\n",
    "\n",
    "dfa = dfa.drop(columns=['Unnamed: 0']).reset_index(drop=True)\n",
    "dfi = dfi.drop(columns=['Unnamed: 0']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert species keys to category IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple conversion\n",
    "\n",
    "dfa['category_id'] = dfa['species'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0, 'name': 'baboon', 'supercategory': ''},\n",
       " {'id': 1, 'name': 'bird', 'supercategory': ''},\n",
       " {'id': 2, 'name': 'buffalo', 'supercategory': ''},\n",
       " {'id': 3, 'name': 'bushpig', 'supercategory': ''},\n",
       " {'id': 4, 'name': 'canoe', 'supercategory': ''},\n",
       " {'id': 5, 'name': 'car', 'supercategory': ''},\n",
       " {'id': 6, 'name': 'crocodile', 'supercategory': ''},\n",
       " {'id': 7, 'name': 'duiker', 'supercategory': ''},\n",
       " {'id': 8, 'name': 'ec3', 'supercategory': ''},\n",
       " {'id': 9, 'name': 'ec4', 'supercategory': ''},\n",
       " {'id': 10, 'name': 'eland', 'supercategory': ''},\n",
       " {'id': 11, 'name': 'elephant', 'supercategory': ''},\n",
       " {'id': 12, 'name': 'elephant bull', 'supercategory': ''},\n",
       " {'id': 13, 'name': 'gazelle_thomsons', 'supercategory': ''},\n",
       " {'id': 14, 'name': 'giraffe', 'supercategory': ''},\n",
       " {'id': 15, 'name': 'hartebeest', 'supercategory': ''},\n",
       " {'id': 16, 'name': 'hippo', 'supercategory': ''},\n",
       " {'id': 17, 'name': 'hyena', 'supercategory': ''},\n",
       " {'id': 18, 'name': 'impala', 'supercategory': ''},\n",
       " {'id': 19, 'name': 'kob', 'supercategory': ''},\n",
       " {'id': 20, 'name': 'kudu', 'supercategory': ''},\n",
       " {'id': 21, 'name': 'lion', 'supercategory': ''},\n",
       " {'id': 22, 'name': 'ostrich', 'supercategory': ''},\n",
       " {'id': 23, 'name': 'puku', 'supercategory': ''},\n",
       " {'id': 24, 'name': 'red lechwe', 'supercategory': ''},\n",
       " {'id': 25, 'name': 'reedbuck', 'supercategory': ''},\n",
       " {'id': 26, 'name': 'roan', 'supercategory': ''},\n",
       " {'id': 27, 'name': 'roof_mabati', 'supercategory': ''},\n",
       " {'id': 28, 'name': 'sable', 'supercategory': ''},\n",
       " {'id': 29, 'name': 'sheep', 'supercategory': ''},\n",
       " {'id': 30, 'name': 'sitatunga', 'supercategory': ''},\n",
       " {'id': 31, 'name': 'steenbok', 'supercategory': ''},\n",
       " {'id': 32, 'name': 'topi', 'supercategory': ''},\n",
       " {'id': 33, 'name': 'unknown animal', 'supercategory': ''},\n",
       " {'id': 34, 'name': 'unknown antelope', 'supercategory': ''},\n",
       " {'id': 35, 'name': 'unknown carcass', 'supercategory': ''},\n",
       " {'id': 36, 'name': 'unknown mammal', 'supercategory': ''},\n",
       " {'id': 37, 'name': 'unknown_carcas', 'supercategory': ''},\n",
       " {'id': 38, 'name': 'unknown_carcass', 'supercategory': ''},\n",
       " {'id': 39, 'name': 'vervet monkey', 'supercategory': ''},\n",
       " {'id': 40, 'name': 'warthog', 'supercategory': ''},\n",
       " {'id': 41, 'name': 'waterbuck', 'supercategory': ''},\n",
       " {'id': 42, 'name': 'white_bones', 'supercategory': ''},\n",
       " {'id': 43, 'name': 'wild dog', 'supercategory': ''},\n",
       " {'id': 44, 'name': 'wildebeest', 'supercategory': ''},\n",
       " {'id': 45, 'name': 'zebra', 'supercategory': ''}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate 'categories' field for the COCO file\n",
    "\n",
    "categories = dfa[['species', 'category_id']].drop_duplicates().to_dict(orient='records')\n",
    "categories = [{'id':item['category_id'], 'name':item['species'], 'supercategory': ''} for item in categories]\n",
    "categories = sorted(categories, key=lambda x: x['id'])\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset down to train and test sets from the processed full dataset above\n",
    "\n",
    "- Note: This certainly violates DRY principle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12299 12299\n",
      "4260 4260\n",
      "(12299, 9) (4260, 11)\n",
      "(14551, 20) (14551, 29)\n"
     ]
    }
   ],
   "source": [
    "## Subset the training set\n",
    "\n",
    "# train_ids = df_train['id_x'].unique()\n",
    "print(len(train_ids), df_train['id_x'].notna().sum())\n",
    "\n",
    "# train_imgids = df_train['id_y'].unique()\n",
    "print(len(train_imgids), df_train['id_y'].nunique())\n",
    "\n",
    "dfa_train = dfa[dfa['id'].isin(train_ids)]\n",
    "dfi_train = dfi[dfi['id'].isin(train_imgids)]\n",
    "print(dfa_train.shape, dfi_train.shape)\n",
    "\n",
    "dfa_train = dfa_train.reset_index(drop=True)\n",
    "dfi_train = dfi_train.reset_index(drop=True)\n",
    "\n",
    "print(dfa_train.merge(dfi_train, left_on='image_id', right_on='id', how='right').shape, df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3181 3181\n",
      "1065 1065\n",
      "(3181, 9) (1065, 11)\n",
      "(3771, 20) (3771, 29)\n"
     ]
    }
   ],
   "source": [
    "## Subset the test set\n",
    "\n",
    "\n",
    "# test_ids = df_test['id_x'].unique()\n",
    "print(len(test_ids), df_test['id_x'].notna().sum())\n",
    "\n",
    "# test = df_test['id_y'].unique()\n",
    "print(len(test_imgids), df_test['id_y'].nunique())\n",
    "\n",
    "dfa_test = dfa[dfa['id'].isin(test_ids)]\n",
    "dfi_test = dfi[dfi['id'].isin(test_imgids)]\n",
    "print(dfa_test.shape, dfi_test.shape)\n",
    "\n",
    "dfa_test = dfa_test.reset_index(drop=True)\n",
    "dfi_test = dfi_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(dfa_test.merge(dfi_test, left_on='image_id', right_on='id', how='right').shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate additional fields from file name\n",
    "\n",
    "- They are currently unused, but kept for the possibility of more detailed analysis after training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi_train['survey_code'] = dfi_train['file_name'].apply(lambda x: x.split('_')[0])\n",
    "dfi_train['aircraft_registration'] = dfi_train['file_name'].apply(lambda x: x.split('_')[1].split('-')[0])\n",
    "dfi_train['camera_side'] = dfi_train['file_name'].apply(lambda x: x.split('_')[1].split('-')[1])\n",
    "dfi_train['flight_session'] = dfi_train['file_name'].apply(lambda x: x.split('_')[2].split('-')[0])\n",
    "dfi_train['exif_timestamp'] = dfi_train['file_name'].apply(lambda x: x.split('_')[2].split('-')[1])\n",
    "dfi_train['orig_file_name'] = dfi_train['file_name'].apply(lambda x: x.split('_')[3].split('.')[0])\n",
    "dfi_train['strat'] = dfi_train['survey_code'] + '_' + dfi_train['aircraft_registration'] + '_' + dfi_train['camera_side'] + '_' + dfi_train['flight_session'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi_test['survey_code'] = dfi_test['file_name'].apply(lambda x: x.split('_')[0])\n",
    "dfi_test['aircraft_registration'] = dfi_test['file_name'].apply(lambda x: x.split('_')[1].split('-')[0])\n",
    "dfi_test['camera_side'] = dfi_test['file_name'].apply(lambda x: x.split('_')[1].split('-')[1])\n",
    "dfi_test['flight_session'] = dfi_test['file_name'].apply(lambda x: x.split('_')[2].split('-')[0])\n",
    "dfi_test['exif_timestamp'] = dfi_test['file_name'].apply(lambda x: x.split('_')[2].split('-')[1])\n",
    "dfi_test['orig_file_name'] = dfi_test['file_name'].apply(lambda x: x.split('_')[3].split('.')[0])\n",
    "dfi_test['strat'] = dfi_test['survey_code'] + '_' + dfi_test['aircraft_registration'] + '_' + dfi_test['camera_side'] + '_' + dfi_test['flight_session'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export image and annot (dfa and dfi) dataframes to coco format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path):\n",
    "    with open(file_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def write_json(data, out_path):\n",
    "    json_object = json.dumps(data, indent=4)\n",
    "    with open(out_path, \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "        \n",
    "def export_annos(dfa, dfi, out_path, categories=[]):\n",
    "    print('out_path', out_path)\n",
    "    print('shapes: ', dfa.shape, dfi.shape)\n",
    "    annos_list = dfa.to_dict(orient='records')\n",
    "    images_list = dfi.to_dict(orient='records')\n",
    "\n",
    "    data = {\n",
    "        'info':{},\n",
    "        'licenses':[],\n",
    "        'images':images_list,\n",
    "        'annotations':annos_list,\n",
    "        'categories':categories\n",
    "           }\n",
    "    write_json(data, out_path)\n",
    "\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_path /media/l3404/43b317c3-b94d-4e83-9199-c98069ecabfc/kaza_files/kaza_export_v0/kaza_train.v0.json\n",
      "shapes:  (12299, 9) (4260, 18)\n",
      "out_path /media/l3404/43b317c3-b94d-4e83-9199-c98069ecabfc/kaza_files/kaza_export_v0/kaza_test.v0.json\n",
      "shapes:  (3181, 9) (1065, 18)\n"
     ]
    }
   ],
   "source": [
    "train_coco_path = export_annos(dfa_train, dfi_train, os.path.join(data_dir, 'kaza_train.v0.json'), categories)\n",
    "test_coco_path = export_annos(dfa_test, dfi_test, os.path.join(data_dir, 'kaza_test.v0.json'), categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
